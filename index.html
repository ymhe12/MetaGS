<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MetaGS: A Meta-Learned Gaussian-Phong Model for Out-of-Distribution 3D Scene Relighting</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">Yumeng He,</span>
                <span class="author-block">
                  <a href="https://wyb15.github.io/" target="_blank">Yunbo Wang</a><sup>†</sup>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=yDEavdMAAAAJ&hl=zh-CN" target="_blank">Xiaokang Yang</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University</span>
                    <span class="eql-cntrb"><small><br><sup>†</sup>Indicates corresponding author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/ymhe12/MetaGS" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2405.20791" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/teaser.mp4"
        type="video/mp4">
      </video>
      <!-- <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2> -->
    </div>
  </div>
</section>
<!-- End teaser video -->


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Out-of-distribution (OOD) 3D relighting requires novel view synthesis under unseen lighting conditions that differ significantly from the observed images. Existing relighting methods, which assume consistent light source distributions between training and testing, often degrade in OOD scenarios. We introduce <b>MetaGS</b> to tackle this challenge from two perspectives. First, we propose a meta-learning approach to train 3D Gaussian splatting, which explicitly promotes learning generalizable Gaussian geometries and appearance attributes across diverse lighting conditions, even with biased training data. Second, we embed fundamental physical priors from the <i>Blinn-Phong</i> reflection model into Gaussian splatting, which enhances the decoupling of shading components and leads to more accurate 3D scene reconstruction. Results on both synthetic and real-world datasets demonstrate the effectiveness of MetaGS in challenging OOD relighting tasks, supporting efficient point-light relighting and generalizing well to unseen environment lighting maps.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Settings -->
<div class="container is-max-desktop">
   <div class="content has-text-left" style="padding: 1.5rem 1.5rem;">
        <h2 class="title is-3">Out-of-distribution Relighting</h2>
        <div class="content has-text-justified">
          <p>
            <b>Out-of-distribution (OOD)</b> refers to cases where <i>test-time light sources deviate from the training distribution</i>.
            As shown below,
            the lighting in the training set is arranged on one side of the hemisphere, 
            while the lighting in the test set is arranged on the opposite side (cameras are located on both sides). 
          </p>
          <div style="text-align: center;">
            <img style="width: 80%;" src="static/images/nrhints_wide.png">
          </div>
        </div>

      </div>
</div>


<!-- Methods -->
<div class="container is-max-desktop">
   <div class="content has-text-left" style="padding: 1.5rem 1.5rem;">
        <h2 class="title is-3">Model Architecture</h2>
        <div class="content has-text-justified">

          <p>
            Our model decomposes the illumination effects by interacting the learned Gaussian points with rays originating
             from both the viewer and the light source.
          </p>
          <div style="text-align: center;">
            <img style="width: 80%;" src="static/images/phong.png">
          </div>

          <p>
            Existing 3D relighting methods exhibit performance degradation when handling out-of-distribution relighting, 
            primarily due to overfitting lighting patterns to perspective-constrained observations, 
            resulting in producing unreasonable lighting components (such as wrong specular and shadows).

            To address this, we draw insights from MAML [1] and introduce a meta-learning framework based on bilevel optimization, 
            which has been shown to effectively bridge the distribution shift between the training and testing domains, 
            facilitating the generalization of optimized variables to unseen scenarios [2].
          </p>
          <div style="text-align: center;">
            <img style="width: 80%;" src="static/images/algorithm.png">
          </div>
          <p>
            [1] Finn, Chelsea, Pieter Abbeel, and Sergey Levine. "Model-agnostic meta-learning for fast adaptation of deep networks." International conference on machine learning. PMLR, 2017.
          <br>
            [2] Chen, Jiaxin, et al. "A closer look at the training strategy for modern meta-learning." Advances in neural information processing systems 33 (2020): 396-406.
          </p>

        </div>
      </div>
</div>

<!-- Results -->
<div class="container is-max-desktop">
   <div class="content has-text-left" style="padding: 1.5rem 1.5rem;">
        <h2 class="title is-3">Results</h2>

        <div class="content has-text-justified">
          <div style="text-align: center;">
            <img style="width: 60%;" src="./static/images/ood_syn.png">
          </div>
          <p>
            <b>Out-of-distribution relighting results on synthetic data:</b>
            We present rendered novel views and error maps. 
            While baselines often misrepresent shadows or light-dependent effects (<i>e.g.</i>, incorrect shadows in <i>Plastic Cup</i>), 
            our model better infers surface appearance.
          </p>
        </div>

        <div class="content has-text-justified">
          <div style="text-align: center;">
            <img style="width: 80%;" src="./static/images/ood_realworld.png">
          </div>
          <p>
            <b>Out-of-distribution relighting results on real-world data:</b>
            As highlighted with the red boxes, baseline models struggle with some level of global shading consistency, 
            such as color shifts, wrong shadows, and floating artifacts.
            Our approach presents physically plausible specular highlights and geometrically consistent shadows that closely match ground truths.
          </p>
        </div>
    </div>
</div>



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@misc{he2025metagsmetalearnedgaussianphongmodel,
      title={MetaGS: A Meta-Learned Gaussian-Phong Model for Out-of-Distribution 3D Scene Relighting}, 
      author={Yumeng He and Yunbo Wang and Xiaokang Yang},
      year={2025},
      eprint={2405.20791},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.20791}, 
}
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This website adapted from <a href="https://nerfies.github.io" target="_blank">Nerfies</a> template. We thank the authors that kindly open sourced the template of this website.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
